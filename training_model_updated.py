# -*- coding: utf-8 -*-
"""
Script d'Entra√Ænement du Mod√®le CNN - Reconnaissance Langue des Signes
Entra√Æne un r√©seau de neurones convolutif pour classifier les signes

Architecture:
- 2 blocs Conv2D + MaxPooling
- Flatten + 2 couches Dense
- Softmax pour classification multi-classes

Compatible avec TensorFlow 2.20 et Keras 3.x
"""

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import os

print("="*60)
print("üß† ENTRA√éNEMENT DU MOD√àLE CNN")
print("="*60)

# Configuration
TRAIN_DIR = 'DataSet/train'
TEST_DIR = 'DataSet/test'
IMAGE_SIZE = (64, 64)
BATCH_SIZE = 5
EPOCHS = 10
NUM_CLASSES = 45  # Nombre total de classes dans le dataset

# V√©rifier que les r√©pertoires existent
print("\n[1/5] V√©rification des r√©pertoires...")
if not os.path.exists(TRAIN_DIR):
    print(f"‚úó Erreur: {TRAIN_DIR} n'existe pas")
    print("Assurez-vous d'avoir cr√©√© le dataset avec data_set_capture.py")
    exit(1)
if not os.path.exists(TEST_DIR):
    print(f"‚úó Erreur: {TEST_DIR} n'existe pas")
    exit(1)

print(f"‚úì R√©pertoire train: {TRAIN_DIR}")
print(f"‚úì R√©pertoire test: {TEST_DIR}")

# √âtape 1: Construction de l'architecture CNN
print("\n[2/5] Construction du mod√®le CNN...")

model = keras.Sequential([
    # Premier bloc de convolution
    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 1)),
    layers.MaxPooling2D(pool_size=(2, 2)),
    
    # Deuxi√®me bloc de convolution
    layers.Conv2D(32, (3, 3), activation='relu'),
    layers.MaxPooling2D(pool_size=(2, 2)),
    
    # Aplatissement
    layers.Flatten(),
    
    # Couches enti√®rement connect√©es
    layers.Dense(128, activation='relu'),
    layers.Dense(NUM_CLASSES, activation='softmax')
], name='SignLanguageCNN')

# Afficher le r√©sum√© de l'architecture
print("\nüìä Architecture du mod√®le:")
model.summary()

# Compilation du mod√®le
print("\n[3/5] Compilation du mod√®le...")
model.compile(
    optimizer='adam',
    loss='categorical_crossentropy',
    metrics=['accuracy']
)
print("‚úì Mod√®le compil√© (optimizer=adam, loss=categorical_crossentropy)")

# √âtape 2: Pr√©paration des donn√©es avec augmentation
print("\n[4/5] Pr√©paration des g√©n√©rateurs de donn√©es...")

# G√©n√©rateur pour les donn√©es d'entra√Ænement (avec augmentation)
train_datagen = ImageDataGenerator(
    rescale=1./255,           # Normalisation
    shear_range=0.2,          # Cisaillement
    zoom_range=0.2,           # Zoom
    horizontal_flip=True      # Retournement horizontal
)

# G√©n√©rateur pour les donn√©es de test (sans augmentation)
test_datagen = ImageDataGenerator(rescale=1./255)

# Chargement des donn√©es d'entra√Ænement
print("\nChargement du training set...")
training_set = train_datagen.flow_from_directory(
    TRAIN_DIR,
    target_size=IMAGE_SIZE,
    batch_size=BATCH_SIZE,
    color_mode='grayscale',
    class_mode='categorical'
)

# Chargement des donn√©es de test
print("Chargement du test set...")
test_set = test_datagen.flow_from_directory(
    TEST_DIR,
    target_size=IMAGE_SIZE,
    batch_size=BATCH_SIZE,
    color_mode='grayscale',
    class_mode='categorical'
)

print(f"\n‚úì Training set: {training_set.samples} images")
print(f"‚úì Test set: {test_set.samples} images")
print(f"‚úì Nombre de classes d√©tect√©es: {training_set.num_classes}")

# √âtape 3: Entra√Ænement du mod√®le
print("\n[5/5] Entra√Ænement du mod√®le...")
print(f"√âpoques: {EPOCHS}")
print(f"Steps par √©poque: 1000")
print(f"Validation steps: 30")
print("\nCela peut prendre plusieurs minutes/heures selon votre GPU...")
print("="*60 + "\n")

# Entra√Æner le mod√®le
history = model.fit(
    training_set,
    steps_per_epoch=1000,
    epochs=EPOCHS,
    validation_data=test_set,
    validation_steps=30,
    verbose=1
)

# Afficher les r√©sultats finaux
print("\n" + "="*60)
print("‚úÖ ENTRA√éNEMENT TERMIN√â!")
print("="*60)
print(f"\nR√©sultats finaux (√©poque {EPOCHS}):")
print(f"  ‚Ä¢ Pr√©cision training:   {history.history['accuracy'][-1]*100:.2f}%")
print(f"  ‚Ä¢ Pr√©cision validation: {history.history['val_accuracy'][-1]*100:.2f}%")
print(f"  ‚Ä¢ Loss training:        {history.history['loss'][-1]:.4f}")
print(f"  ‚Ä¢ Loss validation:      {history.history['val_loss'][-1]:.4f}")

# Sauvegarde du mod√®le
print("\n[6/6] Sauvegarde du mod√®le...")

# Sauvegarder l'architecture en JSON (compatibilit√©)
model_json = model.to_json()
with open("model-bw.json", "w") as json_file:
    json_file.write(model_json)
print("‚úì Architecture sauvegard√©e: model-bw.json")

# Sauvegarder les poids
model.save_weights('model-bw.h5')
print("‚úì Poids sauvegard√©s: model-bw.h5")

# Optionnel: Sauvegarder le mod√®le complet (format moderne)
model.save('model-complete.keras')
print("‚úì Mod√®le complet sauvegard√©: model-complete.keras")

print("\n" + "="*60)
print("üéâ ENTRA√éNEMENT R√âUSSI!")
print("="*60)
print("\nFichiers g√©n√©r√©s:")
print("  ‚Ä¢ model-bw.json   - Architecture du mod√®le")
print("  ‚Ä¢ model-bw.h5     - Poids du mod√®le")
print("  ‚Ä¢ model-complete.keras - Mod√®le complet (optionnel)")
print("\nVous pouvez maintenant utiliser ce mod√®le avec:")
print("  ‚Ä¢ demo_signes_WORKING.py")
print("  ‚Ä¢ app_interface_elegante.py")
print("="*60 + "\n")
